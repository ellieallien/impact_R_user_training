---
title: "IMPACT R user training"
author: ""
date: "21st-22nd May 2019"
output:
  revealjs::revealjs_presentation:
    transition: fade
    css: style.css
    toc: true
---

```{r setup, include=FALSE}
# ioslides_presentation slidy_presentation
knitr::opts_chunk$set(echo = FALSE)
```


## IMPACT 2.0. Strategy: {data-background="background.svg"}
&nbsp;  
&nbsp;  
&nbsp;  
&nbsp; 
- Standardising products and processes  
- Being everywhere  
- Mainstreaming technological tools  

## IMPACT 2.0. Strategy: Data Unit edition {data-background="background.svg"}
&nbsp;  
&nbsp;  
&nbsp;  
&nbsp; 
- Standardising products and processes  
- Being everywhere  
- Mainstreaming technological tools  


**using R and other software to do this**

## ![cbs](./include/working_together.jpg) {data-background="background.svg"}

## For this to happen{data-background="background.svg"}
&nbsp;  
&nbsp;  
&nbsp;  
&nbsp; 
- **Capacity**  
- Processes  
- Sustainable Change  

# Data Unit capacity building framework {data-background="background.svg"}

## ![cbs](./include/capacity_building_scheme.jpg)  {data-background="background.svg"}
## ![cbs](./include/capacity_building_scheme2.jpg) {data-background="background.svg"}
## ![cbs](./include/capacity_building_scheme3.jpg) {data-background="background.svg"}

## After last training {data-background="background.svg"}
&nbsp;
&nbsp;
![cbs](./include/oliver_wow.JPG)

## After last training {data-background="background.svg"}
&nbsp;
&nbsp;
![cbs](./include/hedi_solutions.JPG)

# Dynamic capacity building framework {data-background="background.svg"}

## ![cbs](./include/capacity_building_scheme4.jpg) {data-background="background.svg"}
## ![cbs](./include/capacity_building_scheme5.jpg) {data-background="background.svg"}

# Learning Goals {data-background="background.svg"}

## NOT the learning Goals {data-background="background.svg"}
&nbsp;  
&nbsp;  
&nbsp;  
- *Not* a training on specific tools  
- *Not* a data science degree in 2.5 days  
    - (not statistics)  
    - (not generic R)  
    - (not quantitative research methods)  

## Learning Goals {data-background="background.svg"}
&nbsp;  
&nbsp;  
_"Not a training on specific tools"_

<span style="color:green"> 
*Instead*: how to access and use all current and future (R) tools developed in IMPACT </span>  
(with specific tools as concrete examples) 

&nbsp;
&nbsp;

_"Not a data science degree in 2.5 days"_

<span style="color:green"> 
*Instead*: the first step on your way to becoming a data scientist </span>  
Focused on collaboration, reproducibility, documentation...  


## Agenda {data-background="background.svg"}


**Day1**   
* Intro to R and overview of packages  
&nbsp;  
**Day2**   
* Example Project workflow   
    - with practical exercises for each step  
&nbsp;      
**Day3**  
* Hypothesis tests  
* Certification tests  
&nbsp;  
**Day 4**   
* Brainstorm and Hackathon 


## After this training you will {data-background="background.svg"}

* Know how to **download, load, and use** the core packages at IMPACT  
* (hopefully) be able to transfer that knowledge to your teams  
* Be a part of the IMPACT certified R user community  
&nbsp;  
*R sepcific:  
  - Load packages  
  - Load and save data from R  
  - Access and use documentation  
  - Functions  
  - Basic debugging
  - Collaborate on GitHub  

# Introduction and motivations {data-background="background.svg"}

## Questions! {data-background="background.svg"}

- Questions are everything!
- Might feel hard because there are so MANY easy things at once.
- You are here because you are really talented

## This is a second Pilot {data-background="background.svg"}

- Things will go wrong
- I need your feedback
- No one in the humanitarian system has (successfully) done this before


## Agenda {data-background="background.svg"}

*day 1*  
- 17:00 - 19:00 Introduction / Overview of R packages  

*day 2*   
- 09:00 - 10:30 Sharing R tools at IMPACT *cleaninginspectoR*  
- 11:00 - 13:00 Debugging *koboloops*  
- 14:00 - 14:30 **Working together**  
- 14:30 - 16:30 R environments *koboquest*  
- 17:00 - 19:00 Documentation *surveyweights*  

*day 3*  
- 09:00 - 10:30 Hypothesis tests : why we do them  
- 11:00 - 12:30 Hypothesis tests *HypegrammaR*  
- 12:30 - 13:00 **Certification Test: Work on solutions**  

*day 4*  
- 09:00 - 10:30 Bonus session: Brainstorm

## Mechanics

- The "I dont know how to" board
- Cheatsheets
- Questions: always, no hand raising
- No phones please :) 

## Feedback / questions ? 

# 1.1.3 why R is Powerful

## *a primitive function*: R commands
```{r,echo=T}
sum(1,1)
```

```{r,echo=T}
sum
```

## *a function*: A few lines of code turned into a new command

```{r,include=F}
some_data<-data.frame(some_variable=rnorm(100),another_variable=rnorm(100)+1.5, uuid=sample(letters, 100, rep=T))
```

```{r,echo=TRUE}
colSums(some_data[,c(1:2)])
```

The code behind:
```{r,echo=T}
colSums
```

**THIS CHANGES EVERYTHING!!! WHY?**

## a "complicated" function

```{r, echo=T}
library(keras)
application_resnet50
```

## *Exercise* write a function

A function that takes a numer, adds two and prints the result

## *Exercise* write a function

A function that takes a numer, adds two and prints the result

Things to consider: 
- Arguments 
- Naming your function
- Returning something 

## A package

a collection of functions that solve a specific problem

- Standardised
- Reliable
- Documented
- locked & hidden details
- "Stackable": can be used in other functions/packages
- Shared through a standardised channel

## the Result
![number of R packages](./include/packages_on_cran.png)
[source](https://www.r-bloggers.com/on-the-growth-of-cran-packages/)


## Questions/Feedback?

# Accessing R Packages

```{r,include=FALSE}
library("UpSetR")
movies <- read.csv( system.file("extdata", "movies.csv", package = "UpSetR"), header=T, sep=";" )
mutations <- read.csv( system.file("extdata", "mutations.csv", package = "UpSetR"), header=T, sep = ",")
```

## Finding Packages

- google _"how to .... in R"_
- tutorials
- https://rseek.org/
- https://awesome-r.com/
- https://support.rstudio.com/hc/en-us/articles/201057987-Quick-list-of-useful-R-packages
- the classics: tidyverse, sf, lubridate, survey, magrittr, rmarkdown 

- RStudio conference (youtube)
- Twitter


## Install
```{R,echo=T,eval=F}
install.packages("UpSetR")
```

## Load
```{r,echo=T,eval=F}
library("UpSetR")
```

## Learn
```{r,echo=T,eval=F}
?UpSetR
?upset
```

## Use
```{R,echo=T}
upset(movies, nsets = 6)
```

## Behind the curtains
```{r,echo=T}
upset
```

full source code: google _"PACKAGENAME site:www.github.com"_

## Exercise - Brainstorm

What kind of issues could be solved with a package ? 


# day 2 {data-background="background.svg"}

## Agenda 
- 09:00 - 10:30 R tools at IMPACT **cleaninginspectoR**
- 11:00 - 13:00 Debugging **koboquest** 
- 14:00 - 14:30 Sharing tools: **Hedi's magic**
- 14:30 - 15:00 Adding to the list of requested tools
- 15:30 - 16:30 *koboloops*
- 17:00 - 19:00 R environments **surveyweights**

## Day 1 recap & feedback 

TO BE FILLED

# R Packages on Github

## Project workflow

Water quantity by household varies between 
To see if there is a difference in difficulties of access 

Check data cleaning  
Import questionnaire and choices from kobo 
Merge loops
Calculate weights  
Calculate results

## Gitwhat?

## *git*

### a system to manage code projects

- track and save changes (rewind!)
- manage parallel versions
- merge versions
- collaborate


## *Github*

### an online platform for git

- collaborate online
- share code
- interact with users/developers
      - bug reports
      - feature requests
      - _not_: asking for help (stackoverflow!)


example 1: [This Presentation](https://github.com/ellieallien/impact_R_user_training/)

example 2: [the 2019 MSNA tool](https://github.com/mabafaba/msna18/network)

example 3: [issues (ggplot2)](https://github.com/tidyverse/ggplot2/issues)



## Installing R packages from Github

```{r, eval=F}
install.packages("devtools")
```

```{r, echo=T, eval = F}
devtools::install_github("ellieallien/cleaninginspectoR",
                        build_opts = c()
                        )
```

- "USERNAME/REPOSITORYNAME"
- `build_opts=c()`: makes sure to also download the manual (see `?remotes::install_github`)

## Load 
```{r, eval=T,echo=T,warning=FALSE,message=FALSE}
library("cleaninginspectoR")
```

### Learn

Overview:
```{r,eval=F,echo=T}
?cleaninginspectoR
```
Manuals / Help Documents
```{r,eval=F,echo=T}
browseVignettes("cleaninginspectoR")
```
List all functions
```{r,echo=T,eval=F}
ls("package:cleaninginspectoR")
```
Type `Packagename::` and hit `tab` to see available functions

```{r,echo=F}
knitr::kable(data.frame("contents"=ls("package:cleaninginspectoR")),format="html")
```
Use!
```{r, echo=T}

```
## Solution:
```{r, echo=T, eval = F}
data <- read.csv("./exercise_material/data_clean.csv", stringsAsFactors = F) 
library(tidyr)
data %>% inspect_all(., "X_uuid") %>% write.csv(., "issues.csv")
```

## Bonus

- Create a function for an additional test (enumerator IDs, time spent, ...)

# day 2 {data-background="background.svg"}

## Agenda 
- 09:20 - 10:00 Day 1 review and feedback
- 10:00 - 12:30 Debugging **koboquest** 
- 14:00 - 14:30 Sharing tools: **Hedi's magic**
- 14:30 - 15:00 Adding to the list of requested tools
- 15:30 - 16:30 *koboloops*
- 17:00 - 19:00 R environments **surveyweights**



# Day 1 evening recap

## Creating functions
```{r, echo=T, eval = T}
### Define function
add_two <- function(x = 7){
y <- x+2
return(y)
}

### Call function
add_two(x = 10)
```

## Working with packages

### Install
```{r, echo=T, eval = F}
devtools::install_github("ellieallien/cleaninginspectoR",
                        build_opts = c()
                        )
```

### Load 
```{r, eval=T,echo=T,warning=FALSE,message=FALSE}
library("cleaninginspectoR")
```

### Learn

Overview:
```{r,eval=F,echo=T}
?cleaninginspectoR
```
Manuals / Help Documents
```{r,eval=F,echo=T}
browseVignettes("cleaninginspectoR")
```

## List all functions
```{r,echo=T,eval=T}
ls("package:cleaninginspectoR")
```

## Practical exercise 

## Load 
```{r, eval=T,echo=T,warning=FALSE,message=FALSE}
data <- read.csv("./exercise_material/data_raw.csv", stringsAsFactors = F)
```

What's STRINGS AS FACTORS = FALSE? 

## Loading objects general overview:: 

If you load something into your console it disappears after that line of code  
If you load something into a names object, it stays in your R sessions  
If you load something back onto your computer (for example with write.csv, then it stays on your computer)  

Remember ?
```{r,eval=F,echo=T}
add_two(x = 10)
x
```

Versus
```{r,eval=F,echo=T}
x <- add_two(x = 10)
x
```

## Project plan 

<span style="color:green"> Check data cleaning   </span>
**Import questionnaire and choices** to identify select multiple questions  
**Merge loops** to calculate water supply for each HH  
**Calculate weights** on the fly  
**Calculate results**  

## Getting Started with IMPACT R tools

1. Go to https://rpubs.com/impact_dataunit/impactpackages
2. Follow instructions

## Errors

- Trial and Error is the name of the game
- errors are a conversation!
- if you see an error..
    - check your spelling
    - _read_ the message! Any useful tips?
    - google
    - ask for help
    
## The "debug" function is your best friend

```{r,eval=F,echo=T}
debug(find_duplicates)
undebug(find_duplicates)
```

## PRACTICAL II

- _The Kobo input Tool_
  	- find the package on the repository list: https://rpubs.com/impact_dataunit/impactpackages
  	- install the package (from github)
  	- look at the Documentation file
  	- browse the vignettes; Read the "quickstart" vignette --> if there is none, raise an issue
  	- load your data, then load your survey and choices files (one function in the package does this)
  	
## PRACTICAL II

- What function did this ? where did it put the resulting object?


## PRACTICAL II  	
  	- check the question type of "hh_members_count" "food_source_main" 
  	- save the results to a csv file.

## PRACTICAL II

- _The Kobo input Tool_
  	- "food_source_main" is a select multiple ! list up all its' choices 
  	- save the results to a csv file.


## Solution:
```{r, echo=T, eval = F}
devtools::install_github("mabafaba/koboquest",
                        build_opts = c())
library(koboquest)
?koboquest
data <- read.csv("./exercise_material/data_clean.csv", stringsAsFactors = F)

questionnaire <- load_questionnaire(data, "./exercise_material/questions.csv", "./exercise_material/choices.csv", choices.label.column.to.use = "label")

questionnaire$question_type("latrine.access.problem", data)
ap <- questionnaire$choices_for_select_multiple("latrine.access.problem", data)

latrine_access_problems <- data[,ap]
```



## What can we do with those ? 
```{r, echo=T, eval = F}
percent <- latrine_access_problems %>% apply(., 2, function(x){return(sum(x, na.rm = T)/length(x))})


questionnaire$question_is_select_multiple(names(data))
colSums(latrine_access_problems, na.rm = T)

skipped <- questionnaire$question_is_skipped(data, "refugee.settlement")


agojo <- refugee.settlements$refugee.settlement == "agojo"
sum(agojo) / length(agojo)

refugee.settlements <- data[!skipped,]
```

##Bonus

find all the select multiple questions in the dataset

calculate summary statistics for those 

# ~ COFFEE, TEA, NAPS ~ 


## RECAP 

## Loading objects

Remember ?
```{r,eval=F,echo=T}
add_two(x = 10)
x
```

Versus
```{r,eval=F,echo=T}
x <- add_two(x = 10)
x
```

## Debugging

looking your error up on google
reading the error message 

going through the debug cycle
```{r,eval=F,echo=T}
debug(find_duplicates)
undebug(find_duplicates)
```


## Reading documentation carefully: vignettes 

## Project plan 

<span style="color:green"> Check data cleaning   
**Import questionnaire and choices** to identify select multiple questions   </span>  
**Merge loops** to calculate water supply for each HH  
**Calculate weights** on the fly  
**Calculate results**  

## The challenge

For our WASH analysis, we have to know for each HH how much water they can access from all their containers combined. 
But the containers info is in a different sheet ! 
What to do ??


## Adding the loops data to your data: preparation

```{r, echo=T, eval = F}
devtools::install_github("sharonorengo/koboloops",
                        build_opts = c())
library(koboloops)
browseVignettes("koboloops")

?koboloops::add_parent_to_loop
?koboloops::affect_loop_to_parent
```

## Adding the loops data to your data: execution
```{r, echo=T, eval = F}
main <- read.csv("./exercise_material/data_raw.csv", stringsAsFactors = F)
loops <- read.csv("./exercise_material/water_loop.csv", stringsAsFactors = F)
```
## Adding the loops data to your data: execution
```{r, echo=T, eval = F}
full_data <- koboloops::add_parent_to_loop(loops, main)

full_data_water_info <- koboloops::affect_loop_to_parent(loops, main, aggregate.function = sum,"litres")

full_data_water_info$average_water <- full_data_water_info$Aggregation_Result_litres / full_data_water_info$calc.household

```

## Bonus:

Instead of the total for the household, calculate the average amount of water per hh member.

## Agenda 
- 09:20 - 10:00 Day 1 review and feedback  
  - Assigning results 
- 10:00 - 12:30 Debugging **koboquest** 
  - Looking at your errors  
  - debug(), undebug()  
- 14:00 - 14:30 Sharing tools
- 15:30 - 16:30 Documentations **koboloops**
  - If there is no documentation, check the Vignettes  
  - If the Vignettes aren't enough, check the functions  
  - Look at examples  
  - Dataframes !! 
- 17:00 - 19:00 R environments **surveyweights**


## Project plan

- <span style="color:green"> Check data cleaning   
- **Import questionnaire and choices** to identify select multiple questions  
- **Merge loops** to calculate water supply for each HH  </span>
- **Calculate weights** on the fly
- **Calculate results**

## Getting the weights ready: download

Exercise: 


```{r, echo=T, eval = F}
devtools::install_github("mabafaba/surveyweights",

                        
``` 

```{r, echo=T, eval = T}                        build_opts = c())
library(surveyweights)
??surveyweights
```

## Getting the weights ready: use
```{r, echo=T, eval = T}
samplingframe <- read.csv("./exercise_material/sampling_fr.csv")
data <- read.csv("./exercise_material/data_clean.csv")
```

```{r, echo=T, eval = F}
myweightings <- weighting_fun_from_samplingframe(sampling.frame = samplingframe,
                                            data.stratum.column = "strata",
                                            sampling.frame.population.column = "population",
                                            sampling.frame.stratum.column = "strata")

weights_full <- myweightings(data)
```

## Why not just use weights_full and be done ? 
```{r, echo=T, eval = F}
data$hoh.sex %>% table


  data_fhh <- data %>% filter(hoh.sex == "female")

weights_fhh <- myweightings(data_fhh)
```

```{r, echo=T, eval = F}
weights_fhh %>% table
weights_full %>% table
```

## Bonus: combine with other weights 

# The Quantitative Data Analysis Guidelines

## what they are NOT: How to perform an analysis

## what they ARE (hopefully):

- Approaching data analysis to get meaningful results in context of the research questions/design
- _Which_ statistical procedures you need (.. but not how to perform them) 
- How to interpret the results
- Implications for reporting

## Distinguishing exploratory vs. validatory analysis

- *Exploratory*: Generating hypothesis
- *Validatory*: Refuting hypothesis

## "Torture your data and it will confess to anything"

Mitigation strategies 1/2:

- (predefined hypothesis)
- Transparency
- Generate, then **try to refute** with different data (confirmation bias!)
- _Think hard about what you are going to look at_

## "Torture your data and it will confess to anything"

Mitigation strategies 2/2: Adjusting the critical P-Value
- Bonferroni correction (p_critical_eff = p_critical * num_tests)
- False Discovery Rate
- **problem with this???*
      

## Stats 101

- [There is only one test](http://allendowney.blogspot.com/2011/05/there-is-only-one-test.html)
    - *compute a test statistic* -> effect size
    - *Identify Null hypothesis*: The observed effect size is due to chance
    - *Do a million times*: "Fake" samples from a distribution that matches the null hypothesis
    - *What percentage of those shows an effect size equal or stronger to what we observed?* -> that's a p-value 
    - *Finally: don't do that, use an analytical approximation instead*

## Guidlines: Analysis Cases

    
## Guidlines Structure: What do you want to know?
- Population of interest
- Sampling strategy
- Hypothesis
- Dependent and independent variables
- Data Types
- Hypothesis type
    
=> "Analysis Case" => Appropriate statistics, visualisations, hypothesis tests


## ![analysis flow guidelines](./include/hypegrammaR_flowchart.jpg)


## Interpretation

  - Coherent results: low confidence
  - Coherent results: high confidence
  - Conflicting results: low confidence
  - Conflicting results: high confidence

.. Good data = more accurate results but more importantly
.. Good data = results you *TRUST*


# The hypegrammaR Package

## Project plan

<span style="color:green"> Check data cleaning 
Import data, questionnaire, choices from kobo 
Merge loops 
Calculate weights </span>
**Calculate results**

## Goal

_Enable people to think more about why they do the analysis and what exactly they want to find out and report on, instead of having to know about or work on how to choose and apply the appropriate summary statistics, hypothesis tests and visualisations._


## How?

_If each combination of data types, hypothesis types and sampling strategy can be associated uniquely with an appropriate summary statistic, hypothesis test and visualisation we can..._

## ![analysis flow guidelines](./include/hypegrammaR_flowchart.jpg)

## ![analysis flow hypegrammaR](./include/hypegrammaR_flowchart2.jpg)


## Exercise install and load hypegrammaR


```{r, echo=T, eval = F}
devtools::install_github("ellieallien/hypegrammaR", build_opts = c())

library(hypegrammaR)

browseVignettes("hypegrammaR")
```
See if there is a difference on problems accessing latrines depending on the gender of the head of household


# DAY 4
## SESSION 3.1.1: grand finale
- chamapgne

## SESSION 3.2.2: BONUS SESSION
- rmarkdown: the gold standard of reproducible data science
- custom functions / building tools for yourself