---
title: "IMPACT R user training"
author: ""
date: "8th-11th April 2019"
output:
  revealjs::revealjs_presentation:
    transition: fade
    css: style.css
    toc: true
---

```{r setup, include=FALSE}
# ioslides_presentation slidy_presentation
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_knit$set(root.dir = 'c:/Users/Eliora Henzler/Documents/GitHub/impact_R_user_training/')
```


## IMPACT 2.0. Strategy: {data-background="background.svg"}
&nbsp;  
&nbsp;  
&nbsp;  
&nbsp; 
- Standardising products and processes  
- Increasing collaboration  
- Growing quality of our products

## IMPACT 2.0. Strategy: Data Unit edition {data-background="background.svg"}
&nbsp;  
&nbsp;  
&nbsp;  
&nbsp; 
- Standardising products and processes  
- Increasing collaboration  
- Growing quality of our products

**using R and other software to do this**

## ![cbs](./include/working_together.jpg) {data-background="background.svg"}

## For this to happen{data-background="background.svg"}
&nbsp;  
&nbsp;  
&nbsp;  
&nbsp; 
- **Capacity**  
- Processes  
- Sustainable Change  

# Data Unit capacity building framework {data-background="background.svg"}

## ![cbs](./include/capacity_building_scheme.jpg)  {data-background="background.svg"}
## ![cbs](./include/capacity_building_scheme2.jpg) {data-background="background.svg"}
## ![cbs](./include/capacity_building_scheme3.jpg) {data-background="background.svg"}

## After last training {data-background="background.svg"}
&nbsp;
&nbsp;
![cbs](./include/oliver_wow.JPG)

## After last training {data-background="background.svg"}
&nbsp;
&nbsp;
![cbs](./include/hedi_solutions.JPG)

# Dynamic capacity building framework {data-background="background.svg"}

## ![cbs](./include/capacity_building_scheme4.jpg) {data-background="background.svg"}
## ![cbs](./include/capacity_building_scheme5.jpg) {data-background="background.svg"}

# Learning Goals {data-background="background.svg"}

## NOT the learning Goals {data-background="background.svg"}
&nbsp;
&nbsp;
&nbsp;
- *Not* a training on specific tools  
- *Not* a data science degree in 2.5 days  
    - (not statistics)  
    - (not generic R)  
    - (not quantitative research methods)  

## Learning Goals {data-background="background.svg"}
&nbsp;
&nbsp;
_"Not a training on specific tools"_

<span style="color:green"> 
*Instead*: how to access and use all current and future (R) tools developed in IMPACT </span>  
(with specific tools as concrete examples) 

&nbsp;
&nbsp;

_"Not a data science degree in 2.5 days"_

<span style="color:green"> 
*Instead*: the first step on your way to becoming a data scientist </span>  
Focused on collaboration, reproducibility, documentation...  


## Agenda {data-background="background.svg"}


**Day1**   
* Intro to R and overview of packages  
&nbsp;  
**Day2**   
* Example Project workflow   
    - with practical exercises for each step  
&nbsp;      
**Day3**  
* Hypothesis tests  
* Certification tests  
&nbsp;  
**Day 4**   
* Brainstorm and Hackathon 

## Examples {data-background="background.svg"}
&nbsp;  
- simple data cleaning checks  
- merge kobo data from slightly different tools  
- merge loops into datasets  
- calculate and apply weights  
- analysis of random samples (in line with Guidelines)  
- producing barcharts with error bars  
- visualise intersecting sets  

## After this training you will {data-background="background.svg"}
&nbsp;  
&nbsp;  
&nbsp;  
* Know how to **download, load, and use** the core packages at IMPACT  
* (hopefully) be able to transfer that knowledge to your teams  
* Be a part of the IMPACT certified R user community  

# Introduction and motivations {data-background="background.svg"}

## Questions! {data-background="background.svg"}

- Questions are everything!
- Might feel hard because there are so MANY easy things at once.
- You are here because you are really talented

## This is a second Pilot {data-background="background.svg"}

- Things will go wrong
- I need your feedback
- No one in the humanitarian system has (successfully) done this before


## Agenda {data-background="background.svg"}

*day 1*  
- 17:00 - 19:00 Introduction / Overview of R packages  

*day 2*   
- 09:00 - 10:30 Sharing R tools at IMPACT *cleaninginspectoR*  
- 11:00 - 13:00 Debugging *koboloops*  
- 14:00 - 14:30 **Working together**  
- 14:30 - 16:30 R environments *koboquest*  
- 17:00 - 19:00 Documentation *surveyweights*  

*day 3*  
- 09:00 - 10:30 Hypothesis tests : why we do them  
- 11:00 - 12:30 Hypothesis tests *HypegrammaR*  
- 12:30 - 13:00 **Certification Test: Work on solutions**  

*day 4*  
- 09:00 - 10:30 Bonus session: Brainstorm

## Mechanics

- The "I dont know how to" board
- Cheatsheets
- Questions: always, no hand raising
- No phones please :) 

## Feedback / questions ? 

# 1.1.3 why R is Powerful

## *a primitive function*: R commands
```{r,echo=T}
sum(1,1)
```

```{r,echo=T}
sum
```

## *a function*: A few lines of code turned into a new command

```{r,include=F}
some_data<-data.frame(some_variable=rnorm(100),another_variable=rnorm(100)+1.5, uuid=sample(letters, 100, rep=T))
```

```{r,echo=TRUE}
colSums(some_data[,c(1:2)])
```

The code behind:
```{r,echo=T}
colSums
```

**THIS CHANGES EVERYTHING!!! WHY?**

## a "complicated" function

```{r, echo=T}
library(keras)
application_resnet50
```

## *Exercise* write a function

A function that takes a numer, adds two and prints the result

## *Exercise* write a function

A function that takes a numer, adds two and prints the result

Things to consider: 
- Arguments 
- Naming your function
- Returning something 

## A package

a collection of functions that solve a specific problem

- Standardised
- Reliable
- Documented
- locked & hidden details
- "Stackable": can be used in other functions/packages
- Shared through a standardised channel

## the Result
![number of R packages](./include/packages_on_cran.png)
[source](https://www.r-bloggers.com/on-the-growth-of-cran-packages/)


## Questions/Feedback?

# Accessing R Packages

```{r,include=FALSE}
library("UpSetR")
movies <- read.csv( system.file("extdata", "movies.csv", package = "UpSetR"), header=T, sep=";" )
mutations <- read.csv( system.file("extdata", "mutations.csv", package = "UpSetR"), header=T, sep = ",")
```

## Finding Packages

- google _"how to .... in R"_
- tutorials
- https://rseek.org/
- https://awesome-r.com/
- https://support.rstudio.com/hc/en-us/articles/201057987-Quick-list-of-useful-R-packages
- the classics: tidyverse, sf, lubridate, survey, magrittr, rmarkdown 

- RStudio conference (youtube)
- Twitter


## Install
```{R,echo=T,eval=F}
install.packages("UpSetR")
```

## Load
```{r,echo=T,eval=F}
library("UpSetR")
```

## Learn
```{r,echo=T,eval=F}
?UpSetR
?upset
```

## Use
```{R,echo=T}
upset(movies, nsets = 6)
```

## Behind the curtains
```{r,echo=T}
upset
```

full source code: google _"PACKAGENAME site:www.github.com"_

## Exercise - Brainstorm

What kind of issues could be solved with a package ? 


# day 2 {data-background="background.svg"}

## Agenda 
- 09:00 - 10:30 R tools at IMPACT **cleaninginspectoR**
- 11:00 - 13:00 Debugging **koboquest** 
- 14:00 - 14:30 Sharing tools: **Hedi's magic**
- 14:30 - 15:00 Adding to the list of requested tools
- 15:30 - 16:30 *koboloops*
- 17:00 - 19:00 R environments **surveyweights**

## Day 1 recap & feedback 

TO BE FILLED

# R Packages on Github

## Project workflow

Water quantity by household varies between 
To see if there is a difference in difficulties of access 

Check data cleaning  
Import questionnaire and choices from kobo 
Merge loops
Calculate weights  
Calculate results

## Gitwhat?

## *git*

### a system to manage code projects

- track and save changes (rewind!)
- manage parallel versions
- merge versions
- collaborate


## *Github*

### an online platform for git

- collaborate online
- share code
- interact with users/developers
      - bug reports
      - feature requests
      - _not_: asking for help (stackoverflow!)


example 1: [This Presentation](https://github.com/ellieallien/impact_R_user_training/)

example 2: [the 2019 MSNA tool](https://github.com/mabafaba/msna18/network)

example 3: [issues (ggplot2)](https://github.com/tidyverse/ggplot2/issues)



## Installing R packages from Github

```{r, eval=F}
install.packages("devtools")
```

```{r, echo=T, eval = F}
devtools::install_github("ellieallien/cleaninginspectoR",
                        build_opts = c()
                        )
```

- "USERNAME/REPOSITORYNAME"
- `build_opts=c()`: makes sure to also download the manual (see `?remotes::install_github`)

## Load 
```{r, eval=T,echo=T,warning=FALSE,message=FALSE}
library("cleaninginspectoR")
```

### Learn

Overview:
```{r,eval=F,echo=T}
?cleaninginspectoR
```
Manuals / Help Documents
```{r,eval=F,echo=T}
browseVignettes("cleaninginspectoR")
```
List all functions
```{r,echo=T,eval=F}
ls("package:cleaninginspectoR")
```
Type `Packagename::` and hit `tab` to see available functions

```{r,echo=F}
knitr::kable(data.frame("contents"=ls("package:cleaninginspectoR")),format="html")
```
Use!
```{r, echo=T}

```
## Solution:
```{r, echo=T, eval = F}
data <- read.csv("./exercise_material/data_clean.csv", stringsAsFactors = F) 
library(tidyr)
data %>% inspect_all(., "X_uuid") %>% write.csv(., "issues.csv")
```

## Bonus

- Create a function for an additional test (enumerator IDs, time spent, ...)

# ~ COFFEE / TEE / NAPS ~

## Project plan 

<span style="color:green"> Check data cleaning </span>
**Import questionnaire and choices** to identify select multiple questions
**Merge loops** to calculate water supply for each HH
**Calculate weights** on the fly
**Calculate results**

## Getting Started with IMPACT R tools

1. Go to https://rpubs.com/impact_dataunit/impactpackages
2. Follow instructions

## Errors

- Trial and Error is the name of the game
- errors are a conversation!
- if you see an error..
    - check your spelling
    - _read_ the message! Any useful tips?
    - google
    - ask for help
    
## The "debug" function is your best friend

## PRACTICAL II

- _The Kobo input Tool_
  	- find the package on the repository list: https://rpubs.com/impact_dataunit/impactpackages
  	- install the package (from github)
  	- looks at the Documentation file
  	- browse the vignettes; Read the "quickstart" vignette --> if there is none, raise an issue
  	- load your data, then load your survey and choices files (one function does this)
  	
## PRACTICAL II

- What function did this ? where did it put the resulting object?


## PRACTICAL II  	
  	- check the question type of "hh_members_count" "food_source_main" 
  	- save the results to a csv file.

## PRACTICAL II

- _The Kobo input Tool_
  	- "food_source_main" is a select multiple ! list up all its' choices 
  	- save the results to a csv file.


## Solution:
```{r, echo=F, eval = F}
devtools::install_github("mabafaba/koboquest",
                        build_opts = c())
library(koboquest)
?koboquest
data <- read.csv("./exercise_material/data_clean.csv", stringsAsFactors = F)

questionnaire <- load_questionnaire(data, "./exercise_material/questions.csv", "./exercise_material/choices.csv", choices.label.column.to.use = "label")

questionnaire$question_type("latrine.access.problem", data)
ap <- questionnaire$choices_for_select_multiple("latrine.access.problem", data)

latrine_access_problems <- data[,ap]
```


## What can we do with those ? 
```{r, echo=F, eval = F}
latrine_access_problems %>% apply(., 2, function(x){return(sum(x, na.rm = T)/length(x))})

```

##Bonus

find all the select multiple questions in the dataset
calculate summary statistics for those 

# ~ LUNCH ~ 

## Day 2 morning feedback

TO BE FILLED


## Reading documentation carefully: vignettes 

## Project plan 

<span style="color:green"> Check data cleaning 
**Import questionnaire and choices** to identify select multiple questions </span>
**Merge loops** to calculate water supply for each HH 
**Calculate weights** on the fly
**Calculate results**

## Adding the loops data to your data 

```{r, echo=F, eval = F}
devtools::install_github("sharonorengo/koboloops",
                        build_opts = c())
library(koboloops)
browseVignettes("koboloops")
main <- read.csv("./exercise_material/data_raw.csv")
loops <- read.csv("./exercise_material/water_loop.csv")

full_data <- koboloops::add_parent_to_loop(loops, main)
full_data_water_info <- koboloops::affect_loop_to_parent(loops, main, aggregate.function = sum, c(capacity_for_hh = "capacity"))
```

## Bonus:

TBD

## Project plan

- <span style="color:green"> Check data cleaning   
- **Import questionnaire and choices** to identify select multiple questions  
- **Merge loops** to calculate water supply for each HH  </span>
- **Calculate weights** on the fly
- **Calculate results**

## Getting the weights ready

Exercise: 


```{r, echo=F, eval = F}
devtools::install_github("mabafaba/surveyweights",
                        build_opts = c())
library(surveyweights)
??surveyweights

samplingframe <- read.csv("./exercise_material/sampling_fr.csv")

myweightings <- weighting_fun_from_samplingframe(sampling.frame = samplingframe,
                                            data.stratum.column = "strata",
                                            sampling.frame.population.column = "population",
                                            sampling.frame.stratum.column = "strata")

weights_full <- myweightings(data)
data$hoh.sex %>% table

data_fhh <- data %>% filter(hoh.sex == "female")

weights_fhh <- myweightings(data_fhh)

weights_fhh %>% table
weights_full %>% table
```

## Bonus: combine with other weights 

# The Quantitative Data Analysis Guidelines

## what they are NOT: How to perform an analysis

## what they ARE (hopefully):

- Approaching data analysis to get meaningful results in context of the research questions/design
- _Which_ statistical procedures you need (.. but not how to perform them) 
- How to interpret the results
- Implications for reporting

## Distinguishing exploratory vs. validatory analysis

- *Exploratory*: Generating hypothesis
- *Validatory*: Refuting hypothesis

## "Torture your data and it will confess to anything"

Mitigation strategies 1/2:

- (predefined hypothesis)
- Transparency
- Generate, then **try to refute** with different data (confirmation bias!)
- _Think hard about what you are going to look at_

## "Torture your data and it will confess to anything"

Mitigation strategies 2/2: Adjusting the critical P-Value
- Bonferroni correction (p_critical_eff = p_critical * num_tests)
- False Discovery Rate
- **problem with this???*
      

## Stats 101

- [There is only one test](http://allendowney.blogspot.com/2011/05/there-is-only-one-test.html)
    - *compute a test statistic* -> effect size
    - *Identify Null hypothesis*: The observed effect size is due to chance
    - *Do a million times*: "Fake" samples from a distribution that matches the null hypothesis
    - *What percentage of those shows an effect size equal or stronger to what we observed?* -> that's a p-value 
    - *Finally: don't do that, use an analytical approximation instead*

## Guidlines: Analysis Cases

    
## Guidlines Structure: What do you want to know?
- Population of interest
- Sampling strategy
- Hypothesis
- Dependent and independent variables
- Data Types
- Hypothesis type
    
=> "Analysis Case" => Appropriate statistics, visualisations, hypothesis tests


## ![analysis flow guidelines](./include/hypegrammaR_flowchart.jpg)


## Interpretation

  - Coherent results: low confidence
  - Coherent results: high confidence
  - Conflicting results: low confidence
  - Conflicting results: high confidence

.. Good data = more accurate results but more importantly
.. Good data = results you *TRUST*


# The hypegrammaR Package

## Project plan

<span style="color:green"> Check data cleaning 
Import data, questionnaire, choices from kobo 
Merge loops 
Calculate weights </span>
**Calculate results**

## Goal

_Enable people to think more about why they do the analysis and what exactly they want to find out and report on, instead of having to know about or work on how to choose and apply the appropriate summary statistics, hypothesis tests and visualisations._


## How?

_If each combination of data types, hypothesis types and sampling strategy can be associated uniquely with an appropriate summary statistic, hypothesis test and visualisation we can..._

## ![analysis flow guidelines](./include/hypegrammaR_flowchart.jpg)

## ![analysis flow hypegrammaR](./include/hypegrammaR_flowchart2.jpg)


## Exercise 

Calculate the (weighted) average for respodent age for each district.
See if there is a difference depending on the head of household


# DAY 4
## SESSION 3.1.1: grand finale
- chamapgne

## SESSION 3.2.2: BONUS SESSION
- rmarkdown: the gold standard of reproducible data science
- custom functions / building tools for yourself